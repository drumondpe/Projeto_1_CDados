{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lourenço Meirelles\n",
    "\n",
    "Nome: Lucca Lima\n",
    "\n",
    "Nome: Pedro Drumond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pedro\n",
      "[nltk_data]     Drumond\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#remove preposisões, artigos\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords.append('')\n",
    "\n",
    "#função que aplica a remoção\n",
    "def clean_stopwords(lista):\n",
    "    filtrada = lista[:]\n",
    "    for palavra in lista:\n",
    "        if palavra in stopwords:\n",
    "            filtrada.remove(palavra)\n",
    "    return filtrada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Pedro Drumond\\Documents\\Insper 2o semestre\\CDados\\GitHub_CD\\Projeto_1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Primevideo.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename)\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O Amazon Prime Video é uma plataforma de streaming semelhante à Netflix, na qual você pode acessar um catálogo de filmes, séries, etc... além de disponibilizar outras coisas como o Amazon Prime Music e entre outros.\n",
    "\n",
    "Para classificar, consideramos mensagens \"automáticas\", prontas, divulgando links como 'muito irrelevantes'. Mensagens aleatórias e não relacionadas ao assunto como 'irrelevantes'. Mensagens que elogiassem a plataforma como 'relevantes' e mensagens que elogiassem muito a plataforma como 'muito relevantes'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[\\n!-.:@?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo de texto\n",
    "# Como ele possui caracteres com acentos, precisamos carregar utilizando o encoding=\"utf8\".\n",
    "primevideo = pd.read_excel('Primevideo.xlsx')\n",
    "primevideo.Classificacao = primevideo.Classificacao.astype('int')\n",
    "primevideo_teste = pd.read_excel('Primevideo.xlsx', sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um DF (DataFrame) para cada classificação\n",
    "\n",
    "#Filtra as linhas, separando cada clasificação em um DF sem ter aplicado o 'CleanUp'\n",
    "filtra_linhas = primevideo.Classificacao == 0\n",
    "primevideo_classfic_0_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "filtra_linhas = primevideo.Classificacao == 1\n",
    "primevideo_classfic_1_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 2\n",
    "primevideo_classfic_2_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 3\n",
    "primevideo_classfic_3_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtrada' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a551598f3026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcelula_limpa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcelula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mcelula_limpa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcelula_limpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mlista_com_todos_tuites_limpos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcelula_limpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mlista_primevideo_classfic_0\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcelula_limpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a6aec173ba1b>\u001b[0m in \u001b[0;36mclean_stopwords\u001b[1;34m(lista)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlista\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mfiltrada\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfiltrada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtrada' is not defined"
     ]
    }
   ],
   "source": [
    "#For, criando as listas limpas\n",
    "lista_primevideo_classfic_0 = []\n",
    "lista_primevideo_classfic_1 = []\n",
    "lista_primevideo_classfic_2 = []\n",
    "lista_primevideo_classfic_3 = []\n",
    "\n",
    "lista_com_todos_tuites_limpos = []\n",
    "\n",
    "#Cria a lista lista_primevideo_classfic que possui  as classificações de cada categoria\n",
    "lista_tuites = []\n",
    "for celula in primevideo_classfic_0_raw:\n",
    "    \n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    celula_limpa = clean_stopwords(celula_limpa)\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_0 += celula_limpa.split()\n",
    "\n",
    "for celula in primevideo_classfic_1_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    celula_limpa = clean_stopwords(celula_limpa)\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_1 += celula_limpa.split()\n",
    "\n",
    "for celula in primevideo_classfic_2_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    celula_limpa = clean_stopwords(celula_limpa)\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_2 += celula_limpa.split()\n",
    "\n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    celula_limpa = clean_stopwords(celula_limpa)\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_3 += celula_limpa.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtrada' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3a95bb41b409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtuite\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprimevideo_teste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Teste'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcelula_limpa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcelula_limpa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcelula_limpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlista_tuites\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcelula_limpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a6aec173ba1b>\u001b[0m in \u001b[0;36mclean_stopwords\u001b[1;34m(lista)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlista\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mfiltrada\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfiltrada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtrada' is not defined"
     ]
    }
   ],
   "source": [
    "# cria a lista tuite a partir da planilha Teste\n",
    "for tuite in primevideo_teste['Teste']:\n",
    "    celula_limpa = cleanup(tuite.lower())\n",
    "    celula_limpa = clean_stopwords(celula_limpa)\n",
    "    lista_tuites.append(celula_limpa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo as tabelas para pd.Series\n",
    "classfic_0 = pd.Series(lista_primevideo_classfic_0)\n",
    "classfic_1 = pd.Series(lista_primevideo_classfic_1)\n",
    "classfic_2 = pd.Series(lista_primevideo_classfic_2)\n",
    "classfic_3 = pd.Series(lista_primevideo_classfic_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabelas de contagem de ocorrencias em cada tabela, usando o value_counts()\n",
    "tabela_0 = classfic_0.value_counts()\n",
    "tabela_1 = classfic_1.value_counts()\n",
    "tabela_2 = classfic_2.value_counts()\n",
    "tabela_3 = classfic_3.value_counts()\n",
    "\n",
    "#Juntando todos os tuítes\n",
    "todos_tuites = lista_primevideo_classfic_0 + lista_primevideo_classfic_1 + lista_primevideo_classfic_2 + lista_primevideo_classfic_3\n",
    "#Criando tabela dos tuítes usando o pd.Series\n",
    "todos_tuites_lista = pd.Series(todos_tuites)\n",
    "tabela_todos_tuites = todos_tuites_lista.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ser_0 = len(classfic_0)/len(tabela_todos_tuites)\n",
    "prob_ser_1 = len(classfic_1)/len(tabela_todos_tuites)\n",
    "prob_ser_2 = len(classfic_2)/len(tabela_todos_tuites)\n",
    "prob_ser_3 = len(classfic_3)/len(tabela_todos_tuites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacao_final = []\n",
    "for tuite in lista_tuites:\n",
    "    prob_0 = 1\n",
    "    prob_1 = 1\n",
    "    prob_2 = 1\n",
    "    prob_3 = 1\n",
    "    \n",
    "    #dentro desse FOR teremos: -probabilidade das palavras, -descobre todas as probabilidades, -aplica La Place, -descobre qual a classificacao\n",
    "    for palavra in tuite:\n",
    "        \n",
    "        #LA PLACE\n",
    "        if palavra not in tabela_0:\n",
    "            prob_0 *= 1/(len(classfic_0) + len(tabela_todos_tuites)) \n",
    "            #/todas as palavras na categoria + todas as palavras de todas as categorias (sem repetição)\n",
    "            #acho que não está pegando todas as palavras ta tabela 0           \n",
    "        elif palavra in tabela_0:\n",
    "            prob_0 *= (tabela_0[palavra] + 1)/(len(classfic_0) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_1:\n",
    "            prob_1 *= 1/(len(classfic_1) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso é do 'Treinamento'\n",
    "                          #quantida de palavras na categoria 1 + quantidade de palavras no total\n",
    "        elif palavra in tabela_1:\n",
    "            prob_1 *= (tabela_1[palavra] + 1)/(len(classfic_1) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_2:\n",
    "            prob_2 *= 1/(len(classfic_2) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso é do 'Treinamento'\n",
    "        elif palavra in tabela_2:\n",
    "            prob_2 *= (tabela_2[palavra] + 1)/(len(classfic_2) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_3:\n",
    "            prob_3 *= 1/(len(classfic_3) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso é do 'Treinamento'\n",
    "        elif palavra in tabela_3:\n",
    "            prob_3 *= (tabela_3[palavra] + 1)/(len(classfic_3) + len(tabela_todos_tuites))\n",
    "        \n",
    "    #cálculo das probabilidades\n",
    "    prob_tuite_dado_0 = prob_0 * prob_ser_0\n",
    "    prob_tuite_dado_1 = prob_1 * prob_ser_1\n",
    "    prob_tuite_dado_2 = prob_2 * prob_ser_2\n",
    "    prob_tuite_dado_3 = prob_3 * prob_ser_3\n",
    "\n",
    "    #COMPARAÇÃO ENTRE OS RESULTADOS DE LA PLACE PARA CADA CATEGORIA\n",
    "    if prob_tuite_dado_0 > prob_tuite_dado_1 and prob_tuite_dado_0 > prob_tuite_dado_2 and prob_tuite_dado_0 > prob_tuite_dado_3:\n",
    "        #print(prob_0)\n",
    "        classificacao_final.append(0)\n",
    "        #adicionar na coluna no excel\n",
    "            \n",
    "    elif prob_tuite_dado_1 > prob_tuite_dado_0 and prob_tuite_dado_1 > prob_tuite_dado_2 and prob_tuite_dado_1 > prob_tuite_dado_3:\n",
    "        #print(prob_1)\n",
    "        classificacao_final.append(1)\n",
    "            \n",
    "    elif prob_tuite_dado_2 > prob_tuite_dado_0 and prob_tuite_dado_2 > prob_tuite_dado_1 and prob_tuite_dado_2 > prob_tuite_dado_3:\n",
    "        #print(prob_2)\n",
    "        classificacao_final.append(2)\n",
    "            \n",
    "    elif prob_tuite_dado_3 > prob_tuite_dado_0 and prob_tuite_dado_3 > prob_tuite_dado_1 and prob_tuite_dado_3 > prob_tuite_dado_2:\n",
    "        #print(prob_3)\n",
    "        classificacao_final.append(3)\n",
    "\n",
    "#FAZER ALGUMA COISA COM O 'classificacao_final' QUE É UMA TABELA COM AS CLASSIFICAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICANDO A PERFORMANCE\n",
    "\n",
    "classificacao_final\n",
    "classificacao_final_pd = pd.Series(classificacao_final)\n",
    "primevideo_teste['Resultado Classificador'] = classificacao_final_pd\n",
    "primevideo_teste.tail(20)\n",
    "\n",
    "pd.crosstab(primevideo_teste['Classificação'], primevideo_teste['Resultado Classificador'], margins=True)#linha e coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(primevideo_teste['Classificação'], primevideo_teste['Resultado Classificador'], normalize=True).round(4)*100#linha e coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acurácia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ANÁLISE CRÍTICA:*\n",
    "\n",
    "Nosso classificador conseguiu distinguir bem as classificações entre 0 e 1, provavelmente porque \n",
    "possuem a maior frequência dentre todas as classificações, assim ele \"aprende\" melhor as diferenças \n",
    "dessas duas classificações.\n",
    "Apesar de ele ter acertado algumas entre 2 e 3, sua precisão foi inferior comparado as duas primeiras\n",
    "classificações, provavelmente devido à menor quantidade de tweets dentro dessas classificações, dificultando\n",
    "o \"aprendizado\" do classificador. Porém, mesmo com esse déficit, a maior quantidade foi de acertos.\n",
    "\n",
    "O nosso classificador não é capaz de identificar a diferença das mensagens de dupla negação e sarcasmo.\n",
    "Pois ele avalia as pelavras individualmente, as tirando do contexto da frase (tweet), considerando apenas\n",
    "suas ocorrências.\n",
    "\n",
    "Vocês devem continuar ou melhorar o financiando do nosso projeto porque com o aumento investimento seria\n",
    "possível coletar mais tweets, principalmente de classificação 2 e 3, melhorando o \"aprendizado\" do \n",
    "classificador e possivelmente criar mais classificações, o deixando mais preciso.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*POR QUE NÃO PODEMOS USAR NOSSO CLASSIFICADOR PARA GERAR MAIS AMOSTRAS DE TREINAMENTO?*\n",
    "\n",
    "Não é possível utilizar o classificador para gerar mais amostras de treinamento porque\n",
    "a interpretação dele é diferente da nossa, ele é capaz de aprender as probabilidades\n",
    "das palavras de nossas interpretações, não interpretar.\n",
    "\n",
    "Além disso, ainda há certas coisas que o classificador está categorizando erroneamente, seria possível corrigí-las aumentando a quantidade de tweets em seu aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melhorar - *DIFERENTES CENÁRIOS PARA NAIVE BAYES FORA DO CONTEXTO DO PROJETO:*\n",
    "- Fazer previsões em tempo real\n",
    "- Prever se um usuário gostaria de um determinado recurso ou não"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melhorar - *MELHORIAS REAIS:*\n",
    "- Melhorar os critérios das classificações do aprendizado\n",
    "- Aumentar o número de classificações\n",
    "- Aumentar a quantidade de dados coletados (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CONCEITO B:\n",
    "- Acurácia\n",
    "CONCEITO A:\n",
    "- Melhorar o cleanup()\n",
    "- Corrigir espaçamento nos tuítes\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
