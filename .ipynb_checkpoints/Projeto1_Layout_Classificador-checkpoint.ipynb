{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lourenço Meirelles\n",
    "\n",
    "Nome: Lucca Lima\n",
    "\n",
    "Nome: Pedro Gomes de Sá Drumond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Primevideo.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O Amazon Prime Video é uma plataforma de streaming semelhante à Netflix, na qual você pode acessar um catálogo de filmes, séries, etc... além de disponibilizar outras coisas como o Amazon Prime Music e entre outros.\n",
    "\n",
    "Para classificar, consideramos mensagens que elogiassem a plataforma como relevante, e o resto como irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    #MELHORAR\n",
    "    \n",
    "#tirar '@'\n",
    "#talvez 'e', 'que'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISAMOS DE:\n",
    "\n",
    "#P(mensagens relevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como irrelevantes)\n",
    "#P(mensagens relevantes | classificadas como irrelevantes)\n",
    "#Acurácia ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAR UMA OLHADA EM PANDAS\n",
    "# Carrega o arquivo de texto\n",
    "# Como ele possui caracteres com acentos, precisamos carregar utilizando o encoding=\"utf8\".\n",
    "primevideo = pd.read_excel('Primevideo.xlsx')\n",
    "primevideo.Classificacao = primevideo.Classificacao.astype('int')\n",
    "primevideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um DF (DataFrame) para cada classificação\n",
    "\n",
    "#Filtra as linhas, separando cada clasificação em um DF sem ter aplicado o 'CleanUp'\n",
    "filtra_linhas = primevideo.Classificacao == 0\n",
    "primevideo_classfic_0_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "filtra_linhas = primevideo.Classificacao == 1\n",
    "primevideo_classfic_1_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 2\n",
    "primevideo_classfic_2_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 3\n",
    "primevideo_classfic_3_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "print(primevideo_classfic_0_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANUP - vai precisar do for\n",
    "#cleanup(primevideo_classfic_0_raw[0].lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For, criando as listas limpas\n",
    "lista_primevideo_classfic_0 = []\n",
    "lista_primevideo_classfic_1 = []\n",
    "lista_primevideo_classfic_2 = []\n",
    "lista_primevideo_classfic_3 = []\n",
    "\n",
    "lista_com_todas_palavras = []\n",
    "\n",
    "#Cria a lista lista_primevideo_classfic que possui  as classificações de cada categoria\n",
    "\n",
    "for celula in primevideo_classfic_0_raw:    \n",
    "    lista_tuites = []\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "    lista_classificacao_0 += celula_limpa.split()\n",
    "    \n",
    "    lista_primevideo_classfic_0 += lista_tuites\n",
    "    lista_com_todas_palavras += celula_limpa.split()\n",
    "    print(lista_primevideo_classfic_0)\n",
    "    \n",
    "for celula in primevideo_classfic_1_raw:\n",
    "    lista_tuites = []\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())\n",
    "    lista_primevideo_classfic_1 += lista_tuites\n",
    "    lista_com_todas_palavras += celula_limpa.split()\n",
    "    print(lista_primevideo_classfic_1)\n",
    "    \n",
    "for celula in primevideo_classfic_2_raw:\n",
    "    lista_tuites = []\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())\n",
    "    lista_primevideo_classfic_2 += lista_tuites\n",
    "    lista_com_todas_palavras += celula_limpa.split()\n",
    "    print(lista_primevideo_classfic_2)\n",
    "    \n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    lista_tuites = []\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())\n",
    "    lista_primevideo_classfic_3 += lista_tuites\n",
    "    lista_com_todas_palavras += celula_limpa.split()\n",
    "    print(lista_primevideo_classfic_3)\n",
    "    \n",
    "'''for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower()).split()\n",
    "    lista_primevideo_classfic_3 += celula_limpa\n",
    "    print(lista_primevideo_classfic_3)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo as tabelas para pd.Series\n",
    "print(lista_primevideo_classfic_0)\n",
    "classfic_0 = pd.Series(lista_com_todos_tuites_limpos_classfic_0)\n",
    "classfic_0.value_counts()\n",
    "\n",
    "classfic_1 = pd.Series(lista_primevideo_classfic_1)\n",
    "classfic_1.value_counts()\n",
    "classfic_2 = pd.Series(lista_primevideo_classfic_2)\n",
    "classfic_2.value_counts()\n",
    "classfic_3 = pd.Series(lista_primevideo_classfic_3)\n",
    "classfic_3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabelas de contagem de ocorrencias em cada tabela, usando o value_counts()\n",
    "tabela_classific_0 = classfic_0.value_counts()\n",
    "print(tabela_classific_0)\n",
    "tabela_classific_1 = classfic_1.value_counts()\n",
    "tabela_classific_2 = classfic_2.value_counts()\n",
    "tabela_classific_3 = classfic_3.value_counts()\n",
    "#Juntando todos os tuítes\n",
    "todos_tuites = lista_primevideo_classfic_0 + lista_primevideo_classfic_1 + lista_primevideo_classfic_2 + lista_primevideo_classfic_3\n",
    "#Criando tabela dos tuítes usando o pd.Series\n",
    "todos_tuites_lista = pd.Series(todos_tuites)\n",
    "tabela_todos_tuites = todos_tuites_lista.value_counts()\n",
    "#tabela_todos_tuites\n",
    "\n",
    "lista_com_todas_palavras_pd = pd.Series(lista_com_todas_palavras)\n",
    "palavras_em_todos_tuites_limpos_pd = lista_com_todas_palavras_pd.value_counts()\n",
    "#palavras_em_todos_tuites_limpos_pd\n",
    "\n",
    "#ACHO QUE VAMOS TER QUE USAR TABELA RELATIVA PORQUE TEMOS MAIS AVALIAÇÕES EM UNS DO QUE OUTROS, VER ISSO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Se P(0|tuite) > P(1|tuite) e P(0|tuite) > P(2|tuite) e P(0|tuite) > P(3|tuite):\n",
    "        é 0\n",
    "    Se P(1|tuite) > P(0|tuite) e P(1|tuite) > P(2|tuite) e P(1|tuite) > P(3|tuite):\n",
    "        é 1\n",
    "    Se P(2|tuite) > P(0|tuite) e P(2|tuite) > P(1|tuite) e P(2|tuite) > P(3|tuite):\n",
    "        é 2\n",
    "    Se P(3|tuite) > P(0|tuite) e P(3|tuite) > P(1|tuite) e P(3|tuite) > P(2|tuite):\n",
    "        é e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Começando classificador:\n",
    "\n",
    "# P_0_dado_tuite = P_tuite_dado_0 * P(geral)\n",
    "\n",
    "#acessa cada tuíte feito\n",
    "\n",
    "P_0_dado_tuite = 1\n",
    "for tuite in lista_primevideo_classfic_0:\n",
    "    for palavra in tuite:\n",
    "        #print(tabela_classific_0[0])\n",
    "        P_0_dado_tuite *= tabela_classific_0[str(palavra)]                #ou sem a relativa\n",
    "lista_primevideo_classfic_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_primevideo_classfic_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tem que fazer para cada linha \n",
    "#CLASSIFICADOR#\n",
    "\n",
    "#passa por cada tuíte\n",
    "for tuite in todos_tuites.Treinamento:\n",
    "    #P(tuite|classificacao)\n",
    "    P_tuite_dado_classificacao_0 = todos_tuites_relativa[tuite] * \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
