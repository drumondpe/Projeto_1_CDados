{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Louren√ßo Meirelles\n",
    "\n",
    "Nome: Lucca Lima\n",
    "\n",
    "Nome: Pedro Drumond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Pedro Drumond\\Documents\\Insper 2o semestre\\CDados\\GitHub_CD\\Projeto_1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Primevideo.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"eu sou mais eu\" n√£o tem roteiro criativo, par...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#nineperfectstrangers \\ns√©rie muito boa no @pr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#primevideo  quero uma sequ√™ncia pra ontem de ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo amei p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo bravo!üëè</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0  \"eu sou mais eu\" n√£o tem roteiro criativo, par...              2\n",
       "1  #nineperfectstrangers \\ns√©rie muito boa no @pr...              3\n",
       "2  #primevideo  quero uma sequ√™ncia pra ontem de ...              2\n",
       "3  @camila_cabello @cinderella @primevideo amei p...              3\n",
       "4    @camila_cabello @cinderella @primevideo bravo!üëè              3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@janainadobrasil esse daqui √© a melhor op√ß√£o p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@camila_cabello @primevideo ficou lindo, te amo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo linda!...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo ta lin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camilizecabello @mannytsakanika @cinderella @...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  @janainadobrasil esse daqui √© a melhor op√ß√£o p...              1\n",
       "1    @camila_cabello @primevideo ficou lindo, te amo              2\n",
       "2  @camila_cabello @cinderella @primevideo linda!...              3\n",
       "3  @camila_cabello @cinderella @primevideo ta lin...              3\n",
       "4  @camilizecabello @mannytsakanika @cinderella @...              2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O Amazon Prime Video √© uma plataforma de streaming semelhante √† Netflix, na qual voc√™ pode acessar um cat√°logo de filmes, s√©ries, etc... al√©m de disponibilizar outras coisas como o Amazon Prime Music e entre outros.\n",
    "\n",
    "Para classificar, consideramos mensagens \"autom√°ticas\", prontas, divulgando links como 'muito irrelevantes'. Mensagens aleat√≥rias e n√£o relacionadas ao assunto como 'irrelevantes'. Mensagens que elogiassem a plataforma como 'relevantes' e mensagens que elogiassem muito a plataforma como 'muito relevantes'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[\\n!-.:@?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    #MELHORAR\n",
    "    \n",
    "#tirar '@'\n",
    "#talvez 'e', 'que'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISAMOS DE:\n",
    "\n",
    "#P(mensagens relevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como irrelevantes)\n",
    "#P(mensagens relevantes | classificadas como irrelevantes)\n",
    "#Acur√°cia ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@janainadobrasil esse daqui √© a melhor op√ß√£o p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@camila_cabello @primevideo ficou lindo, te amo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo linda!...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo ta lin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camilizecabello @mannytsakanika @cinderella @...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>lan√ßamentos do prime video em setembro de 2021...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>j√° √© tarde demais para dizer que cinderella, d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>@teamyoutube minha tv (sony) e meu celular (sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@anyborgesreal @dougfrn baseado no caso ritcho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>n√£o precisou da pirataria, meus amigos ricos m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o\n",
       "0    @janainadobrasil esse daqui √© a melhor op√ß√£o p...              1\n",
       "1      @camila_cabello @primevideo ficou lindo, te amo              2\n",
       "2    @camila_cabello @cinderella @primevideo linda!...              3\n",
       "3    @camila_cabello @cinderella @primevideo ta lin...              3\n",
       "4    @camilizecabello @mannytsakanika @cinderella @...              2\n",
       "..                                                 ...            ...\n",
       "294  lan√ßamentos do prime video em setembro de 2021...              0\n",
       "295  j√° √© tarde demais para dizer que cinderella, d...              1\n",
       "296  @teamyoutube minha tv (sony) e meu celular (sa...              1\n",
       "297  @anyborgesreal @dougfrn baseado no caso ritcho...              0\n",
       "298  n√£o precisou da pirataria, meus amigos ricos m...              1\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DAR UMA OLHADA EM PANDAS\n",
    "# Carrega o arquivo de texto\n",
    "# Como ele possui caracteres com acentos, precisamos carregar utilizando o encoding=\"utf8\".\n",
    "primevideo = pd.read_excel('Primevideo.xlsx')\n",
    "primevideo.Classificacao = primevideo.Classificacao.astype('int')\n",
    "primevideo\n",
    "primevideo_teste = pd.read_excel('Primevideo.xlsx', sheet_name=1)\n",
    "primevideo_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      @artofesthetic baseado no caso ritchofen, dois...\n",
      "1      @laressa baseado no caso ritchofen, dois filme...\n",
      "2      @popzonebr baseado no caso ritchofen, dois fil...\n",
      "3      @bbb @gshow baseado no caso ritchofen, dois fi...\n",
      "4      @flamengo @davidluiz_4 baseado no caso ritchof...\n",
      "                             ...                        \n",
      "142    @paulaamorim baseado no caso ritchofen, dois f...\n",
      "143    @eulaurakeller @valescaoficial baseado no caso...\n",
      "144    @sepcarloslima @acordadebora um crime real, do...\n",
      "145    @acordadebora um crime real, dois filmes e dua...\n",
      "146    @rolealeatorio baseado no caso ritchofen, dois...\n",
      "Name: Treinamento, Length: 147, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Criar um DF (DataFrame) para cada classifica√ß√£o\n",
    "\n",
    "#Filtra as linhas, separando cada clasifica√ß√£o em um DF sem ter aplicado o 'CleanUp'\n",
    "filtra_linhas = primevideo.Classificacao == 0\n",
    "primevideo_classfic_0_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "filtra_linhas = primevideo.Classificacao == 1\n",
    "primevideo_classfic_1_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 2\n",
    "primevideo_classfic_2_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 3\n",
    "primevideo_classfic_3_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "print(primevideo_classfic_0_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANUP - vai precisar do for\n",
    "#cleanup(primevideo_classfic_0_raw[0].lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 4]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = [1, 3]\n",
    "b = [1, 4]\n",
    "print(a+b)\n",
    "c = b.append(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor celula in primevideo_classfic_3_raw:\\n    celula_limpa = cleanup(celula.lower()).split()\\n    lista_primevideo_classfic_3 += celula_limpa\\n    print(lista_primevideo_classfic_3)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For, criando as listas limpas\n",
    "lista_primevideo_classfic_0 = []\n",
    "lista_primevideo_classfic_1 = []\n",
    "lista_primevideo_classfic_2 = []\n",
    "lista_primevideo_classfic_3 = []\n",
    "\n",
    "lista_com_todos_tuites_limpos = []\n",
    "\n",
    "#Cria a lista lista_primevideo_classfic que possui  as classifica√ß√µes de cada categoria\n",
    "lista_tuites = []\n",
    "for celula in primevideo_classfic_0_raw:\n",
    "    \n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_0 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_0)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_1_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_1 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_1)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_2_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_2 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_2)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_3 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_3)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "'''\n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower()).split()\n",
    "    lista_primevideo_classfic_3 += celula_limpa\n",
    "    print(lista_primevideo_classfic_3)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuite in primevideo_teste['Teste']:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e                        115\n",
      "que                       96\n",
      "matou                     82\n",
      "pais                      82\n",
      "prime                     79\n",
      "                        ... \n",
      "https//tco/jbksppqtar      1\n",
      "resolver                   1\n",
      "https//tco/npjvfkbv1c      1\n",
      "eisenbahn                  1\n",
      "a√≠                         1\n",
      "Length: 853, dtype: int64\n",
      "##############################################\n",
      "prime                    96\n",
      "o                        70\n",
      "primevideo               69\n",
      "e                        68\n",
      "a                        65\n",
      "                         ..\n",
      "disney/star               1\n",
      "interest                  1\n",
      "https//tco/5bnmn8wldq     1\n",
      "jap√£o                     1\n",
      "blusas                    1\n",
      "Length: 1295, dtype: int64\n",
      "##############################################\n",
      "primevideo        72\n",
      "camila_cabello    51\n",
      "e                 34\n",
      "de                34\n",
      "a                 33\n",
      "                  ..\n",
      "mudan√ßa            1\n",
      "aproveito          1\n",
      "tb                 1\n",
      "americanos         1\n",
      "boc√≥               1\n",
      "Length: 616, dtype: int64\n",
      "##############################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a                        41\n",
       "primevideo               33\n",
       "o                        31\n",
       "e                        31\n",
       "prime                    28\n",
       "                         ..\n",
       "https//tco/ek2ujy65gm     1\n",
       "preferida                 1\n",
       "hoje                      1\n",
       "streamings                1\n",
       "deixe                     1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertendo as tabelas para pd.Series\n",
    "\n",
    "classfic_0 = pd.Series(lista_primevideo_classfic_0)\n",
    "print(classfic_0.value_counts())\n",
    "print('##############################################')\n",
    "classfic_1 = pd.Series(lista_primevideo_classfic_1)\n",
    "print(classfic_1.value_counts())\n",
    "print('##############################################')\n",
    "classfic_2 = pd.Series(lista_primevideo_classfic_2)\n",
    "print(classfic_2.value_counts())\n",
    "print('##############################################')\n",
    "classfic_3 = pd.Series(lista_primevideo_classfic_3)\n",
    "classfic_3.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e             248\n",
       "prime         225\n",
       "primevideo    208\n",
       "a             207\n",
       "que           198\n",
       "             ... \n",
       "mag             1\n",
       "momü•∞ü•∞           1\n",
       "utilizada       1\n",
       "modelos         1\n",
       "julie           1\n",
       "Length: 2552, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabelas de contagem de ocorrencias em cada tabela, usando o value_counts()\n",
    "tabela_classific_0 = classfic_0.value_counts()\n",
    "tabela_classific_1 = classfic_1.value_counts()\n",
    "tabela_classific_2 = classfic_2.value_counts()\n",
    "tabela_classific_3 = classfic_3.value_counts()\n",
    "\n",
    "#Juntando todos os tu√≠tes\n",
    "todos_tuites = lista_primevideo_classfic_0 + lista_primevideo_classfic_1 + lista_primevideo_classfic_2 + lista_primevideo_classfic_3\n",
    "#Criando tabela dos tu√≠tes usando o pd.Series\n",
    "todos_tuites_lista = pd.Series(todos_tuites)\n",
    "tabela_todos_tuites = todos_tuites_lista.value_counts()\n",
    "tabela_todos_tuites\n",
    "#tabela_classific_0\n",
    "\n",
    "#ACHO QUE VAMOS TER QUE USAR TABELA RELATIVA PORQUE TEMOS MAIS AVALIA√á√ïES EM UNS DO QUE OUTROS, VER ISSO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e                        115\n",
       "que                       96\n",
       "matou                     82\n",
       "pais                      82\n",
       "prime                     79\n",
       "                        ... \n",
       "https//tco/jbksppqtar      1\n",
       "resolver                   1\n",
       "https//tco/npjvfkbv1c      1\n",
       "eisenbahn                  1\n",
       "a√≠                         1\n",
       "Length: 853, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_0 = classfic_0.value_counts()\n",
    "tabela_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prime                    96\n",
       "o                        70\n",
       "primevideo               69\n",
       "e                        68\n",
       "a                        65\n",
       "                         ..\n",
       "disney/star               1\n",
       "interest                  1\n",
       "https//tco/5bnmn8wldq     1\n",
       "jap√£o                     1\n",
       "blusas                    1\n",
       "Length: 1295, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_1 = classfic_1.value_counts()\n",
    "tabela_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primevideo        72\n",
       "camila_cabello    51\n",
       "e                 34\n",
       "de                34\n",
       "a                 33\n",
       "                  ..\n",
       "mudan√ßa            1\n",
       "aproveito          1\n",
       "tb                 1\n",
       "americanos         1\n",
       "boc√≥               1\n",
       "Length: 616, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_2 = classfic_2.value_counts()\n",
    "tabela_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a                        41\n",
       "primevideo               33\n",
       "o                        31\n",
       "e                        31\n",
       "prime                    28\n",
       "                         ..\n",
       "https//tco/ek2ujy65gm     1\n",
       "preferida                 1\n",
       "hoje                      1\n",
       "streamings                1\n",
       "deixe                     1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_3 = classfic_3.value_counts()\n",
    "tabela_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rolealeatorio',\n",
       " 'baseado',\n",
       " 'no',\n",
       " 'caso',\n",
       " 'ritchofen',\n",
       " 'dois',\n",
       " 'filmes',\n",
       " 'e',\n",
       " 'duas',\n",
       " 'vers√µes',\n",
       " 'a',\n",
       " 'menina',\n",
       " 'que',\n",
       " 'matou',\n",
       " 'os',\n",
       " 'pais',\n",
       " 'e',\n",
       " 'o',\n",
       " 'menino',\n",
       " 'que',\n",
       " 'matou',\n",
       " 'meus',\n",
       " 'pais']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuite = '@rolealeatorio baseado no caso ritchofen, dois filmes e duas vers√µes: a menina que matou os pais e o menino que matou meus pais'\n",
    "tuite = cleanup(tuite.lower())\n",
    "tuite.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRECISAMOS FAZER:\\n\\n- La Place\\n- Comparar as classifica√ß√µes\\n- An√°lise cr√≠tica da da performance\\n\\n\\n-LA PLACE:\\n\\n    -temos que tirar tudo de relativo\\n    -quantidade de palavras na categoria + 1 / quantidade de palavras na categoria + quantidade de palavras ao todo\\n\\n\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PRECISAMOS FAZER:\n",
    "\n",
    "- La Place\n",
    "- Comparar as classifica√ß√µes\n",
    "- An√°lise cr√≠tica da da performance\n",
    "\n",
    "\n",
    "-LA PLACE:\n",
    "\n",
    "    -temos que tirar tudo de relativo\n",
    "    -quantidade de palavras na categoria + 1 / quantidade de palavras na categoria + quantidade de palavras ao todo\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabela de palavras sem as repeti√ß√µes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacao_final = []\n",
    "for tuite in lista_tuites:\n",
    "    prob_0 = 1\n",
    "    prob_1 = 1\n",
    "    prob_2 = 1\n",
    "    prob_3 = 1\n",
    "    \n",
    "    #dentro desse FOR teremos: -probabilidade das palavras, -descobre todas as probabilidades, -aplica La Place, -descobre qual a classificacao\n",
    "    for palavra in tuite:\n",
    "        \n",
    "        if palavra not in tabela_0:\n",
    "            prob_0 *= 1/(len(classfic_0) + len(tabela_todos_tuites)) \n",
    "            #          /todas as palavras na categoria + todas as palavras de todas as categorias (sem repeti√ß√£o)\n",
    "            #          acho que n√£o est√° pegando todas as palavras ta tabela 0           \n",
    "            \n",
    "        elif palavra in tabela_0:\n",
    "            prob_0 *= (tabela_0[palavra] + 1)/(len(classfic_0) + len(tabela_todos_tuites))\n",
    "        '''\n",
    "        prob_palavras_dado_0 *= tabela_0[palavra]\n",
    "        prob_1 *= tabela_1[palavra]\n",
    "        prob_2 *= tabela_2[palavra]\n",
    "        prob_3 *= tabela_3[palavra]\n",
    "        '''\n",
    "        \n",
    "        if palavra not in tabela_1:\n",
    "            prob_1 *= 1/(len(classfic_1) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "                          #quantida de palavras na categoria 1 + quantidade de palavras no total\n",
    "        elif palavra in tabela_1:\n",
    "            prob_1 *= (tabela_1[palavra] + 1)/(len(classfic_1) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_2:\n",
    "            prob_2 *= 1/(len(classfic_2) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "        elif palavra in tabela_2:\n",
    "            prob_2 *= (tabela_2[palavra] + 1)/(len(classfic_2) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_3:\n",
    "            prob_3 *= 1/(len(classfic_3) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "        elif palavra in tabela_3:\n",
    "            prob_3 *= (tabela_3[palavra] + 1)/(len(classfic_3) + len(tabela_todos_tuites))\n",
    "        \n",
    "        \n",
    "        # denominador: ocorrencia da palavra na categoria + 1 / todas as palavras na categoria + todas as palavras de todas as categorias (sem repeti√ß√£o)\n",
    "        # prob_A_dado_B = prob_B_dado_A * prob_A\n",
    "        \n",
    "        \n",
    "        #Chama fun√ß√£o que faz o calculo de P_classifica√ß√£o_dado_tuite:\n",
    "        \n",
    "        #prob_0_dado_tuite = prob_0 * ( len(tabela_0) / len(tabela_todos_tuites )\n",
    "        #                                                        esse len() est√° errado\n",
    "        \n",
    "        '''\n",
    "        prob_0_dado_tuite = calcula_prob_classific_dado_tuite(prob_0, len(tabela_0), len(tabela_todos_tuites))\n",
    "        prob_1_dado_tuite = calcula_prob_classific_dado_tuite(prob_1, len(tabela_1), len(tabela_todos_tuites))\n",
    "        prob_2_dado_tuite = calcula_prob_classific_dado_tuite(prob_2, len(tabela_2), len(tabela_todos_tuites))\n",
    "        prob_3_dado_tuite = calcula_prob_classific_dado_tuite(prob_3, len(tabela_3), len(tabela_todos_tuites))\n",
    "        '''\n",
    "                                      \n",
    "\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if prob_0_dado_tuite > prob_1_dado_tuite and prob_0_dado_tuite > prob_2_dado_tuite and prob_0_dado_tuite > prob_3_dado_tuite:\n",
    "            print(prob_0_dado_tuite)\n",
    "            classificacao_final.append(0)\n",
    "            #adicionar na coluna no excel\n",
    "            \n",
    "        elif prob_1_dado_tuite > prob_0_dado_tuite and prob_1_dado_tuite > prob_2_dado_tuite and prob_1_dado_tuite > proprob_3_dado_tuite:\n",
    "            print(prob_1_dado_tuite)\n",
    "            classificacao_final.append(1)\n",
    "            \n",
    "        elif prob_2_dado_tuite > prob_0_dado_tuite and prob_2_dado_tuite > prob_1_dado_tuite and prob_2_dado_tuite > prob_3_dado_tuite:\n",
    "            print(prob_2_dado_tuite)\n",
    "            classificacao_final.append(2)\n",
    "            \n",
    "        elif prob_3_dado_tuite > prob_0_dado_tuite and prob_3_dado_tuite > prob_1_dado_tuite and prob_3_dado_tuite > prob_1_dado_tuite:\n",
    "            print(prob_3_dado_tuite)\n",
    "            classificacao_final.append(3)\n",
    "        '''\n",
    "            \n",
    "\n",
    "#FAZER ALGUMA COISA COM O 'classificacao_final' QUE √â UMA TABELA COM AS CLASSIFICA√á√ïES\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_prob_classific_dado_tuite(prob_classific, tamanho_tabela_classific_sem_repeticoes, tamanho_tabela_todos_tuites_repeticoes):\n",
    "    prob_classific_dado_tuite = prob_classific * (tamanho_tabela_classific_sem_repeticoes / tamanho_tabela_todos_tuites_repeticoes)\n",
    "    return prob_classific_dado_tuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef funcao_classificadora(tuite):\\n    \\n    prob_inicial_0 = 1\\n    prob_inicial_1 = 1\\n    prob_inicial_2 = 1\\n    prob_inicial_3 = 1\\n    \\n    for palavra in tuite.split():\\n        if tabela_0_relativa[palavra] > 0:\\n            prob_0 = tabela_0_relativa[palavra] * prob_inicial_0\\n        if tabela_1_relativa[palavra] > 0:\\n            prob_1 = tabela_1_relativa[palavra] * prob_inicial_1\\n        if tabela_2_relativa[palavra] > 0:\\n            prob_2 = tabela_2_relativa[palavra] * prob_inicial_2\\n        if tabela_3_relativa[palavra] > 0:\\n            prob_3 = tabela_3_relativa[palavra] * prob_inicial_3\\n        else:\\n            return 'n√£o h√° essa palavra na database'\\n            \\n    if prob_0 > prob_1 and prob_0 > prob_2 and prob_0 > prob_3:\\n        print(prob_0)\\n        return 0\\n    elif prob_1 > prob_0 and prob_1 > prob_2 and prob_1 > prob_3:\\n        print(prob_1)\\n        return 1\\n    elif prob_2 > prob_0 and prob_2 > prob_1 and prob_2 > prob_3:\\n        print(prob_2)\\n        return 2\\n    elif prob_3 > prob_0 and prob_3 > prob_1 and prob_3 > prob_1:\\n        print(prob_3)\\n        return 3\\n\\nprint(funcao_classificadora(tuite))\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Come√ßando classificador:\n",
    "'''\n",
    "def funcao_classificadora(tuite):\n",
    "    \n",
    "    prob_inicial_0 = 1\n",
    "    prob_inicial_1 = 1\n",
    "    prob_inicial_2 = 1\n",
    "    prob_inicial_3 = 1\n",
    "    \n",
    "    for palavra in tuite.split():\n",
    "        if tabela_0_relativa[palavra] > 0:\n",
    "            prob_0 = tabela_0_relativa[palavra] * prob_inicial_0\n",
    "        if tabela_1_relativa[palavra] > 0:\n",
    "            prob_1 = tabela_1_relativa[palavra] * prob_inicial_1\n",
    "        if tabela_2_relativa[palavra] > 0:\n",
    "            prob_2 = tabela_2_relativa[palavra] * prob_inicial_2\n",
    "        if tabela_3_relativa[palavra] > 0:\n",
    "            prob_3 = tabela_3_relativa[palavra] * prob_inicial_3\n",
    "        else:\n",
    "            return 'n√£o h√° essa palavra na database'\n",
    "            \n",
    "    if prob_0 > prob_1 and prob_0 > prob_2 and prob_0 > prob_3:\n",
    "        print(prob_0)\n",
    "        return 0\n",
    "    elif prob_1 > prob_0 and prob_1 > prob_2 and prob_1 > prob_3:\n",
    "        print(prob_1)\n",
    "        return 1\n",
    "    elif prob_2 > prob_0 and prob_2 > prob_1 and prob_2 > prob_3:\n",
    "        print(prob_2)\n",
    "        return 2\n",
    "    elif prob_3 > prob_0 and prob_3 > prob_1 and prob_3 > prob_1:\n",
    "        print(prob_3)\n",
    "        return 3\n",
    "\n",
    "print(funcao_classificadora(tuite))\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-72-aa83ca2c9342>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-72-aa83ca2c9342>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    P_tuite_dado_classificacao_0 = todos_tuites_relativa[tuite] *\u001b[0m\n\u001b[1;37m                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Tem que fazer para cada linha \n",
    "#CLASSIFICADOR#\n",
    "\n",
    "#passa por cada tu√≠te\n",
    "for tuite in todos_tuites.Treinamento:\n",
    "    #P(tuite|classificacao)\n",
    "    P_tuite_dado_classificacao_0 = todos_tuites_relativa[tuite] * \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
