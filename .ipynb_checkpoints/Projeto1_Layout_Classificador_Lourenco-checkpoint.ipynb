{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Louren√ßo Meirelles\n",
    "\n",
    "Nome: Lucca Lima\n",
    "\n",
    "Nome: Pedro Drumond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Pedro Drumond\\Documents\\Insper 2o semestre\\CDados\\GitHub_CD\\Projeto_1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Primevideo.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"eu sou mais eu\" n√£o tem roteiro criativo, par...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#nineperfectstrangers \\ns√©rie muito boa no @pr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#primevideo  quero uma sequ√™ncia pra ontem de ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo amei p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo bravo!üëè</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0  \"eu sou mais eu\" n√£o tem roteiro criativo, par...              2\n",
       "1  #nineperfectstrangers \\ns√©rie muito boa no @pr...              3\n",
       "2  #primevideo  quero uma sequ√™ncia pra ontem de ...              2\n",
       "3  @camila_cabello @cinderella @primevideo amei p...              3\n",
       "4    @camila_cabello @cinderella @primevideo bravo!üëè              3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@janainadobrasil esse daqui √© a melhor op√ß√£o p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@camila_cabello @primevideo ficou lindo, te amo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo linda!...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo ta lin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camilizecabello @mannytsakanika @cinderella @...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  @janainadobrasil esse daqui √© a melhor op√ß√£o p...              2\n",
       "1    @camila_cabello @primevideo ficou lindo, te amo              2\n",
       "2  @camila_cabello @cinderella @primevideo linda!...              3\n",
       "3  @camila_cabello @cinderella @primevideo ta lin...              3\n",
       "4  @camilizecabello @mannytsakanika @cinderella @...              2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O Amazon Prime Video √© uma plataforma de streaming semelhante √† Netflix, na qual voc√™ pode acessar um cat√°logo de filmes, s√©ries, etc... al√©m de disponibilizar outras coisas como o Amazon Prime Music e entre outros.\n",
    "\n",
    "Para classificar, consideramos mensagens que elogiassem a plataforma como relevante, e o resto como irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[\\n!-.:@?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    #MELHORAR\n",
    "    \n",
    "#tirar '@'\n",
    "#talvez 'e', 'que'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISAMOS DE:\n",
    "\n",
    "#P(mensagens relevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como relevantes)\n",
    "#P(mensagens irrelevantes | classificadas como irrelevantes)\n",
    "#P(mensagens relevantes | classificadas como irrelevantes)\n",
    "#Acur√°cia ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@janainadobrasil esse daqui √© a melhor op√ß√£o p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@camila_cabello @primevideo ficou lindo, te amo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo linda!...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camila_cabello @cinderella @primevideo ta lin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camilizecabello @mannytsakanika @cinderella @...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>lan√ßamentos do prime video em setembro de 2021...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>j√° √© tarde demais para dizer que cinderella, d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>@teamyoutube minha tv (sony) e meu celular (sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@anyborgesreal @dougfrn baseado no caso ritcho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>n√£o precisou da pirataria, meus amigos ricos m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o\n",
       "0    @janainadobrasil esse daqui √© a melhor op√ß√£o p...              2\n",
       "1      @camila_cabello @primevideo ficou lindo, te amo              2\n",
       "2    @camila_cabello @cinderella @primevideo linda!...              3\n",
       "3    @camila_cabello @cinderella @primevideo ta lin...              3\n",
       "4    @camilizecabello @mannytsakanika @cinderella @...              2\n",
       "..                                                 ...            ...\n",
       "294  lan√ßamentos do prime video em setembro de 2021...              0\n",
       "295  j√° √© tarde demais para dizer que cinderella, d...              1\n",
       "296  @teamyoutube minha tv (sony) e meu celular (sa...              1\n",
       "297  @anyborgesreal @dougfrn baseado no caso ritcho...              0\n",
       "298  n√£o precisou da pirataria, meus amigos ricos m...              1\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DAR UMA OLHADA EM PANDAS\n",
    "# Carrega o arquivo de texto\n",
    "# Como ele possui caracteres com acentos, precisamos carregar utilizando o encoding=\"utf8\".\n",
    "primevideo = pd.read_excel('Primevideo.xlsx')\n",
    "primevideo.Classificacao = primevideo.Classificacao.astype('int')\n",
    "primevideo\n",
    "primevideo_teste = pd.read_excel('Primevideo.xlsx', sheet_name=1)\n",
    "primevideo_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      @artofesthetic baseado no caso ritchofen, dois...\n",
      "1      @laressa baseado no caso ritchofen, dois filme...\n",
      "2      @popzonebr baseado no caso ritchofen, dois fil...\n",
      "3      @bbb @gshow baseado no caso ritchofen, dois fi...\n",
      "4      @flamengo @davidluiz_4 baseado no caso ritchof...\n",
      "                             ...                        \n",
      "142    @paulaamorim baseado no caso ritchofen, dois f...\n",
      "143    @eulaurakeller @valescaoficial baseado no caso...\n",
      "144    @sepcarloslima @acordadebora um crime real, do...\n",
      "145    @acordadebora um crime real, dois filmes e dua...\n",
      "146    @rolealeatorio baseado no caso ritchofen, dois...\n",
      "Name: Treinamento, Length: 147, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Criar um DF (DataFrame) para cada classifica√ß√£o\n",
    "\n",
    "#Filtra as linhas, separando cada clasifica√ß√£o em um DF sem ter aplicado o 'CleanUp'\n",
    "filtra_linhas = primevideo.Classificacao == 0\n",
    "primevideo_classfic_0_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "filtra_linhas = primevideo.Classificacao == 1\n",
    "primevideo_classfic_1_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 2\n",
    "primevideo_classfic_2_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "filtra_linhas = primevideo.Classificacao == 3\n",
    "primevideo_classfic_3_raw = primevideo.loc[filtra_linhas, 'Treinamento'].reset_index(drop=True)\n",
    "\n",
    "print(primevideo_classfic_0_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANUP - vai precisar do for\n",
    "#cleanup(primevideo_classfic_0_raw[0].lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 4]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = [1, 3]\n",
    "b = [1, 4]\n",
    "print(a+b)\n",
    "c = b.append(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor celula in primevideo_classfic_3_raw:\\n    celula_limpa = cleanup(celula.lower()).split()\\n    lista_primevideo_classfic_3 += celula_limpa\\n    print(lista_primevideo_classfic_3)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For, criando as listas limpas\n",
    "lista_primevideo_classfic_0 = []\n",
    "lista_primevideo_classfic_1 = []\n",
    "lista_primevideo_classfic_2 = []\n",
    "lista_primevideo_classfic_3 = []\n",
    "\n",
    "lista_com_todos_tuites_limpos = []\n",
    "\n",
    "#Cria a lista lista_primevideo_classfic que possui  as classifica√ß√µes de cada categoria\n",
    "lista_tuites = []\n",
    "for celula in primevideo_classfic_0_raw:\n",
    "    \n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_0 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_0)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_1_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_1 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_1)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_2_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_2 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_2)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_com_todos_tuites_limpos += celula_limpa\n",
    "    lista_primevideo_classfic_3 += celula_limpa.split()\n",
    "    #print(lista_primevideo_classfic_3)\n",
    "    #lista_tuites.append(celula_limpa.split())\n",
    "    \n",
    "'''\n",
    "for celula in primevideo_classfic_3_raw:\n",
    "    celula_limpa = cleanup(celula.lower()).split()\n",
    "    lista_primevideo_classfic_3 += celula_limpa\n",
    "    print(lista_primevideo_classfic_3)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuite in primevideo_teste['Teste']:\n",
    "    celula_limpa = cleanup(celula.lower())\n",
    "    lista_tuites.append(celula_limpa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e             115\n",
      "que            96\n",
      "matou          82\n",
      "pais           82\n",
      "prime          79\n",
      "             ... \n",
      "diferen√ßas      1\n",
      "danstorani      1\n",
      "starplus        1\n",
      "entinsider      1\n",
      "direitos        1\n",
      "Length: 853, dtype: int64\n",
      "##############################################\n",
      "prime         96\n",
      "o             70\n",
      "primevideo    69\n",
      "e             68\n",
      "a             65\n",
      "              ..\n",
      "perfeita       1\n",
      "elenco         1\n",
      "leve           1\n",
      "mamada         1\n",
      "servindo       1\n",
      "Length: 1295, dtype: int64\n",
      "##############################################\n",
      "primevideo        72\n",
      "camila_cabello    51\n",
      "de                34\n",
      "e                 34\n",
      "a                 33\n",
      "                  ..\n",
      "foda               1\n",
      "diverte            1\n",
      "gotas              1\n",
      "aqui               1\n",
      "m√£e                1\n",
      "Length: 616, dtype: int64\n",
      "##############################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a               41\n",
       "primevideo      33\n",
       "o               31\n",
       "e               31\n",
       "prime           28\n",
       "                ..\n",
       "foda             1\n",
       "ar               1\n",
       "literalmente     1\n",
       "lan√ßou           1\n",
       "oie_patricia     1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertendo as tabelas para pd.Series\n",
    "\n",
    "classfic_0 = pd.Series(lista_primevideo_classfic_0)\n",
    "print(classfic_0.value_counts())\n",
    "print('##############################################')\n",
    "classfic_1 = pd.Series(lista_primevideo_classfic_1)\n",
    "print(classfic_1.value_counts())\n",
    "print('##############################################')\n",
    "classfic_2 = pd.Series(lista_primevideo_classfic_2)\n",
    "print(classfic_2.value_counts())\n",
    "print('##############################################')\n",
    "classfic_3 = pd.Series(lista_primevideo_classfic_3)\n",
    "classfic_3.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e             248\n",
       "prime         225\n",
       "primevideo    208\n",
       "a             207\n",
       "que           198\n",
       "             ... \n",
       "assistidas      1\n",
       "phoebe          1\n",
       "irei            1\n",
       "dead            1\n",
       "1¬™              1\n",
       "Length: 2552, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabelas de contagem de ocorrencias em cada tabela, usando o value_counts()\n",
    "tabela_classific_0 = classfic_0.value_counts()\n",
    "tabela_classific_1 = classfic_1.value_counts()\n",
    "tabela_classific_2 = classfic_2.value_counts()\n",
    "tabela_classific_3 = classfic_3.value_counts()\n",
    "\n",
    "#Juntando todos os tu√≠tes\n",
    "todos_tuites = lista_primevideo_classfic_0 + lista_primevideo_classfic_1 + lista_primevideo_classfic_2 + lista_primevideo_classfic_3\n",
    "#Criando tabela dos tu√≠tes usando o pd.Series\n",
    "todos_tuites_lista = pd.Series(todos_tuites)\n",
    "tabela_todos_tuites = todos_tuites_lista.value_counts()\n",
    "tabela_todos_tuites\n",
    "#tabela_classific_0\n",
    "\n",
    "#ACHO QUE VAMOS TER QUE USAR TABELA RELATIVA PORQUE TEMOS MAIS AVALIA√á√ïES EM UNS DO QUE OUTROS, VER ISSO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e             115\n",
       "que            96\n",
       "matou          82\n",
       "pais           82\n",
       "prime          79\n",
       "             ... \n",
       "diferen√ßas      1\n",
       "danstorani      1\n",
       "starplus        1\n",
       "entinsider      1\n",
       "direitos        1\n",
       "Length: 853, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_0 = classfic_0.value_counts()\n",
    "tabela_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prime         96\n",
       "o             70\n",
       "primevideo    69\n",
       "e             68\n",
       "a             65\n",
       "              ..\n",
       "perfeita       1\n",
       "elenco         1\n",
       "leve           1\n",
       "mamada         1\n",
       "servindo       1\n",
       "Length: 1295, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_1 = classfic_1.value_counts()\n",
    "tabela_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primevideo        72\n",
       "camila_cabello    51\n",
       "de                34\n",
       "e                 34\n",
       "a                 33\n",
       "                  ..\n",
       "foda               1\n",
       "diverte            1\n",
       "gotas              1\n",
       "aqui               1\n",
       "m√£e                1\n",
       "Length: 616, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_2 = classfic_2.value_counts()\n",
    "tabela_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a               41\n",
       "primevideo      33\n",
       "o               31\n",
       "e               31\n",
       "prime           28\n",
       "                ..\n",
       "foda             1\n",
       "ar               1\n",
       "literalmente     1\n",
       "lan√ßou           1\n",
       "oie_patricia     1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_3 = classfic_3.value_counts()\n",
    "tabela_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rolealeatorio',\n",
       " 'baseado',\n",
       " 'no',\n",
       " 'caso',\n",
       " 'ritchofen',\n",
       " 'dois',\n",
       " 'filmes',\n",
       " 'e',\n",
       " 'duas',\n",
       " 'vers√µes',\n",
       " 'a',\n",
       " 'menina',\n",
       " 'que',\n",
       " 'matou',\n",
       " 'os',\n",
       " 'pais',\n",
       " 'e',\n",
       " 'o',\n",
       " 'menino',\n",
       " 'que',\n",
       " 'matou',\n",
       " 'meus',\n",
       " 'pais']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuite = '@rolealeatorio baseado no caso ritchofen, dois filmes e duas vers√µes: a menina que matou os pais e o menino que matou meus pais'\n",
    "tuite = cleanup(tuite.lower())\n",
    "tuite.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRECISAMOS FAZER:\\n\\n- La Place\\n- Comparar as classifica√ß√µes\\n- An√°lise cr√≠tica da da performance\\n\\n\\n-LA PLACE:\\n\\n    -temos que tirar tudo de relativo\\n    -quantidade de palavras na categoria + 1 / quantidade de palavras na categoria + quantidade de palavras ao todo\\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PRECISAMOS FAZER:\n",
    "\n",
    "- La Place\n",
    "- Comparar as classifica√ß√µes\n",
    "- An√°lise cr√≠tica da da performance\n",
    "\n",
    "\n",
    "-LA PLACE:\n",
    "\n",
    "    -temos que tirar tudo de relativo\n",
    "    -quantidade de palavras na categoria + 1 / quantidade de palavras na categoria + quantidade de palavras ao todo\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'suymayi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4410\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4411\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4412\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3e5c19b0ea78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mprob_3\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabela_3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabela_todos_tuites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtabela_3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mprob_3\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtabela_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabela_3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabela_todos_tuites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4417\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4418\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4419\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4420\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4421\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'suymayi'"
     ]
    }
   ],
   "source": [
    "classificacao_final = []\n",
    "for tuite in lista_tuites:\n",
    "    prob_0 = 1\n",
    "    prob_1 = 1\n",
    "    prob_2 = 1\n",
    "    prob_3 = 1\n",
    "    \n",
    "    for palavra in tuite:    \n",
    "        if palavra not in tabela_0:\n",
    "            prob_0 *= 1/(len(tabela_0) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "            \n",
    "        elif palavra in tabela_0:\n",
    "            prob_0 *= (tabela_0[palavra] + 1)/(len(tabela_0) + len(tabela_todos_tuites))\n",
    "        \n",
    "        \n",
    "        '''prob_0 *= tabela_0[palavra]\n",
    "        prob_1 *= tabela_1[palavra]\n",
    "        prob_2 *= tabela_2[palavra]\n",
    "        prob_3 *= tabela_3[palavra]'''\n",
    "        \n",
    "        if palavra not in tabela_1:\n",
    "            prob_1 *= 1/(len(tabela_1) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "                          #quantida de palavras na categoria 1 + quantidade de palavras no total\n",
    "        elif palavra in tabela_1:\n",
    "            prob_1 *= (tabela_1[palavra] + 1)/(len(tabela_1) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_2:\n",
    "            prob_2 *= 1/(len(tabela_2) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "        elif palavra in tabela_2:\n",
    "            prob_2 *= (tabela_2[palavra] + 1)/(len(tabela_2) + len(tabela_todos_tuites))\n",
    "        \n",
    "        if palavra not in tabela_3:\n",
    "            prob_3 *= 1/(len(tabela_3) + len(tabela_todos_tuites)) #talvez seja a tabela errada, rever porque isso √© do 'Treinamento'\n",
    "        elif palavra in tabela_3:\n",
    "            prob_3 *= (tabela_2[palavra] + 1)/(len(tabela_3) + len(tabela_todos_tuites))\n",
    "        \n",
    "        \n",
    "        '''if prob_0 > prob_1 and prob_0 > prob_2 and prob_0 > prob_3:\n",
    "            print(prob_0)\n",
    "            classificacao_final.append(0)\n",
    "            #adicionar na coluna no excel\n",
    "            \n",
    "        elif prob_1 > prob_0 and prob_1 > prob_2 and prob_1 > prob_3:\n",
    "            print(prob_1)\n",
    "            classificacao_final.append(1)\n",
    "            \n",
    "        elif prob_2 > prob_0 and prob_2 > prob_1 and prob_2 > prob_3:\n",
    "            print(prob_2)\n",
    "            classificacao_final.append(2)\n",
    "            \n",
    "        elif prob_3 > prob_0 and prob_3 > prob_1 and prob_3 > prob_1:\n",
    "            print(prob_3)\n",
    "            classificacao_final.append(3)'''\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Come√ßando classificador:\n",
    "'''\n",
    "def funcao_classificadora(tuite):\n",
    "    \n",
    "    prob_inicial_0 = 1\n",
    "    prob_inicial_1 = 1\n",
    "    prob_inicial_2 = 1\n",
    "    prob_inicial_3 = 1\n",
    "    \n",
    "    for palavra in tuite.split():\n",
    "        if tabela_0_relativa[palavra] > 0:\n",
    "            prob_0 = tabela_0_relativa[palavra] * prob_inicial_0\n",
    "        if tabela_1_relativa[palavra] > 0:\n",
    "            prob_1 = tabela_1_relativa[palavra] * prob_inicial_1\n",
    "        if tabela_2_relativa[palavra] > 0:\n",
    "            prob_2 = tabela_2_relativa[palavra] * prob_inicial_2\n",
    "        if tabela_3_relativa[palavra] > 0:\n",
    "            prob_3 = tabela_3_relativa[palavra] * prob_inicial_3\n",
    "        else:\n",
    "            return 'n√£o h√° essa palavra na database'\n",
    "            \n",
    "    if prob_0 > prob_1 and prob_0 > prob_2 and prob_0 > prob_3:\n",
    "        print(prob_0)\n",
    "        return 0\n",
    "    elif prob_1 > prob_0 and prob_1 > prob_2 and prob_1 > prob_3:\n",
    "        print(prob_1)\n",
    "        return 1\n",
    "    elif prob_2 > prob_0 and prob_2 > prob_1 and prob_2 > prob_3:\n",
    "        print(prob_2)\n",
    "        return 2\n",
    "    elif prob_3 > prob_0 and prob_3 > prob_1 and prob_3 > prob_1:\n",
    "        print(prob_3)\n",
    "        return 3\n",
    "\n",
    "print(funcao_classificadora(tuite))\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tem que fazer para cada linha \n",
    "#CLASSIFICADOR#\n",
    "\n",
    "#passa por cada tu√≠te\n",
    "for tuite in todos_tuites.Treinamento:\n",
    "    #P(tuite|classificacao)\n",
    "    P_tuite_dado_classificacao_0 = todos_tuites_relativa[tuite] * \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
